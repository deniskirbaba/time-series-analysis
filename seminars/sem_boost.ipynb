{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:11:46.492379Z",
          "start_time": "2022-10-13T16:11:33.555822Z"
        },
        "id": "L1EqtpHwMhD2"
      },
      "outputs": [],
      "source": [
        "import lightgbm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:12:12.858218Z",
          "start_time": "2022-10-13T16:12:12.835280Z"
        },
        "id": "Wpo1S0UfRyoc"
      },
      "outputs": [],
      "source": [
        "def plot_series(time, series, format=\"-\", start=0, end=None):\n",
        "    \"\"\"\n",
        "    Visualizes time series data\n",
        "\n",
        "    Args:\n",
        "      time (array of int) - contains the time steps\n",
        "      series (array of int) - contains the measurements for each time step\n",
        "      format - line style when plotting the graph\n",
        "      label - tag for the line\n",
        "      start - first time step to plot\n",
        "      end - last time step to plot\n",
        "    \"\"\"\n",
        "\n",
        "    # Setup dimensions of the graph figure\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    if type(series) is tuple:\n",
        "\n",
        "      for series_num in series:\n",
        "        # Plot the time series data\n",
        "        plt.plot(time[start:end], series_num[start:end], format)\n",
        "\n",
        "    else:\n",
        "      # Plot the time series data\n",
        "      plt.plot(time[start:end], series[start:end], format)\n",
        "\n",
        "    # Label the x-axis\n",
        "    plt.xlabel(\"Time\")\n",
        "\n",
        "    # Label the y-axis\n",
        "    plt.ylabel(\"Value\")\n",
        "\n",
        "    # Overlay a grid on the graph\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Draw the graph on screen\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nk1l6rCEwFK1"
      },
      "source": [
        "Создание рядов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:12:26.185868Z",
          "start_time": "2022-10-13T16:12:26.149929Z"
        },
        "id": "Gos26mZwwF66"
      },
      "outputs": [],
      "source": [
        "def trend(time, slope=0):\n",
        "    \"\"\"\n",
        "    Generates synthetic data that follows a straight line given a slope value.\n",
        "\n",
        "    Args:\n",
        "      time (array of int) - contains the time steps\n",
        "      slope (float) - determines the direction and steepness of the line\n",
        "\n",
        "    Returns:\n",
        "      series (array of float) - measurements that follow a straight line\n",
        "    \"\"\"\n",
        "\n",
        "    # Compute the linear series given the slope\n",
        "    series = slope * time\n",
        "\n",
        "    return series\n",
        "\n",
        "def seasonal_pattern(season_time):\n",
        "    \"\"\"\n",
        "    Just an arbitrary pattern, you can change it if you wish\n",
        "\n",
        "    Args:\n",
        "      season_time (array of float) - contains the measurements per time step\n",
        "\n",
        "    Returns:\n",
        "      data_pattern (array of float) -  contains revised measurement values according\n",
        "                                  to the defined pattern\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate the values using an arbitrary pattern\n",
        "    data_pattern = np.where(season_time < 0.4,\n",
        "                    np.cos(season_time * 2 * np.pi),\n",
        "                    1 / np.exp(3 * season_time))\n",
        "\n",
        "    return data_pattern\n",
        "\n",
        "def seasonality(time, period, amplitude=1, phase=0):\n",
        "    \"\"\"\n",
        "    Repeats the same pattern at each period\n",
        "\n",
        "    Args:\n",
        "      time (array of int) - contains the time steps\n",
        "      period (int) - number of time steps before the pattern repeats\n",
        "      amplitude (int) - peak measured value in a period\n",
        "      phase (int) - number of time steps to shift the measured values\n",
        "\n",
        "    Returns:\n",
        "      data_pattern (array of float) - seasonal data scaled by the defined amplitude\n",
        "    \"\"\"\n",
        "\n",
        "    # Define the measured values per period\n",
        "    season_time = ((time + phase) % period) / period\n",
        "\n",
        "    # Generates the seasonal data scaled by the defined amplitude\n",
        "    data_pattern = amplitude * seasonal_pattern(season_time)\n",
        "\n",
        "    return data_pattern\n",
        "\n",
        "def noise(time, noise_level=1, seed=None):\n",
        "    \"\"\"Generates a normally distributed noisy signal\n",
        "\n",
        "    Args:\n",
        "      time (array of int) - contains the time steps\n",
        "      noise_level (float) - scaling factor for the generated signal\n",
        "      seed (int) - number generator seed for repeatability\n",
        "\n",
        "    Returns:\n",
        "      noise (array of float) - the noisy signal\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize the random number generator\n",
        "    rnd = np.random.RandomState(seed)\n",
        "\n",
        "    # Generate a random number for each time step and scale by the noise level\n",
        "    noise = rnd.randn(len(time)) * noise_level\n",
        "\n",
        "    return noise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsI6IxHvNXmF"
      },
      "source": [
        "## Generate the synthetic data\n",
        "\n",
        "\n",
        "Создадим набор с трендом и годовой сезонностью."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:12:30.869104Z",
          "start_time": "2022-10-13T16:12:30.325038Z"
        },
        "id": "gqWabzlJ63nL"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "time = np.arange(4 * 365 + 1, dtype=\"float32\")\n",
        "baseline = 10\n",
        "amplitude = 40\n",
        "slope = 0.05\n",
        "noise_level = 5\n",
        "\n",
        "# Create the series\n",
        "series = baseline + trend(time, slope) + seasonality(time, period=365, amplitude=amplitude)\n",
        "\n",
        "# Update with noise\n",
        "series += noise(time, noise_level, seed=42)\n",
        "\n",
        "# Plot the results\n",
        "plot_series(time, series)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfdyqJJ1VZVu"
      },
      "source": [
        "## Split the Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:12:44.189735Z",
          "start_time": "2022-10-13T16:12:44.168751Z"
        },
        "id": "_w0eKap5uFNP"
      },
      "outputs": [],
      "source": [
        "# Define the split time\n",
        "split_time = 1000\n",
        "\n",
        "# Get the train set\n",
        "time_train = time[:split_time]\n",
        "x_train = series[:split_time]\n",
        "\n",
        "# Get the validation set\n",
        "time_valid = time[split_time:]\n",
        "x_valid = series[split_time:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:13:03.514680Z",
          "start_time": "2022-10-13T16:13:03.168636Z"
        },
        "id": "qH84AOTOSnxr"
      },
      "outputs": [],
      "source": [
        "# Plot the train set\n",
        "plot_series(time_train, x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:13:04.786444Z",
          "start_time": "2022-10-13T16:13:04.459603Z"
        },
        "id": "YS3D4YpqSl3n"
      },
      "outputs": [],
      "source": [
        "# Plot the validation set\n",
        "plot_series(time_valid, x_valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjD8ncEZbjEW"
      },
      "source": [
        "# Naive Forecast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:13:43.614574Z",
          "start_time": "2022-10-13T16:13:43.594631Z"
        },
        "id": "oXERXJD92OqD"
      },
      "outputs": [],
      "source": [
        "# Generate the naive forecast\n",
        "naive_forecast = series[split_time - 1:-1]\n",
        "\n",
        "# Define time step\n",
        "time_step = 100\n",
        "\n",
        "# Print values\n",
        "print(f'ground truth at time step {time_step}: {x_valid[time_step]}')\n",
        "print(f'prediction at time step {time_step + 1}: {naive_forecast[time_step + 1]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:13:44.920892Z",
          "start_time": "2022-10-13T16:13:44.561271Z"
        },
        "id": "Vk51IA7z1Ym9"
      },
      "outputs": [],
      "source": [
        "# Plot the results\n",
        "plot_series(time_valid, (x_valid, naive_forecast))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:13:49.008505Z",
          "start_time": "2022-10-13T16:13:48.569711Z"
        },
        "id": "D0MKg7FNug9V"
      },
      "outputs": [],
      "source": [
        "# Zooming in\n",
        "plot_series(time_valid, (x_valid, naive_forecast), start=0, end=150)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uh_7244Gsxfx"
      },
      "source": [
        "### Computing Metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:13:58.919892Z",
          "start_time": "2022-10-13T16:13:58.749348Z"
        },
        "id": "byNnC7IbsnMZ"
      },
      "outputs": [],
      "source": [
        "print(tf.keras.metrics.mse(x_valid, naive_forecast).numpy())\n",
        "print(tf.keras.metrics.mae(x_valid, naive_forecast).numpy())\n",
        "print(tf.keras.metrics.mape(x_valid, naive_forecast).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGPBC9QttI1u"
      },
      "source": [
        "## Moving Average"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:16:59.347894Z",
          "start_time": "2022-10-13T16:16:59.324958Z"
        },
        "id": "YGz5UsUdf2tV"
      },
      "outputs": [],
      "source": [
        "def moving_average_forecast(series, window_size):\n",
        "    \"\"\"Generates a moving average forecast\n",
        "\n",
        "    Args:\n",
        "      series (array of float) - contains the values of the time series\n",
        "      window_size (int) - the number of time steps to compute the average for\n",
        "\n",
        "    Returns:\n",
        "      forecast (array of float) - the moving average forecast\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize a list\n",
        "    forecast = []\n",
        "\n",
        "    # Compute the moving average based on the window size\n",
        "    for time in range(len(series) - window_size):\n",
        "      forecast.append(series[time:time + window_size].mean())\n",
        "\n",
        "    # Convert to a numpy array\n",
        "    forecast = np.array(forecast)\n",
        "\n",
        "    return forecast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:17:02.125037Z",
          "start_time": "2022-10-13T16:17:01.739228Z"
        },
        "id": "HHFhGXQji7_r"
      },
      "outputs": [],
      "source": [
        "# Generate the moving average forecast\n",
        "moving_avg = moving_average_forecast(series, 30)[split_time - 30:]\n",
        "\n",
        "# Plot the results\n",
        "plot_series(time_valid, (x_valid, moving_avg))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:17:30.217974Z",
          "start_time": "2022-10-13T16:17:30.187056Z"
        },
        "id": "wG7pTAd7z0e8"
      },
      "outputs": [],
      "source": [
        "# Compute the metrics\n",
        "print(tf.keras.metrics.mse(x_valid, moving_avg).numpy())\n",
        "print(tf.keras.metrics.mae(x_valid, moving_avg).numpy())\n",
        "print(tf.keras.metrics.mape(x_valid, moving_avg).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTD4ATkFYNZp"
      },
      "source": [
        "## Differencing\n",
        "\n",
        "Сделаем дифференцирование t - 365"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:19:27.647874Z",
          "start_time": "2022-10-13T16:19:27.283458Z"
        },
        "id": "5pqySF7-rJR4"
      },
      "outputs": [],
      "source": [
        "# Subtract the values at t-365 from original series\n",
        "diff_series = (series[365:] - series[:-365])\n",
        "\n",
        "# Truncate the first 365 time steps\n",
        "diff_time = time[365:]\n",
        "\n",
        "# Plot the results\n",
        "plot_series(diff_time, diff_series)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:19:56.340282Z",
          "start_time": "2022-10-13T16:19:55.953315Z"
        },
        "id": "QmZpz7arsjbb"
      },
      "outputs": [],
      "source": [
        "# Generate moving average from the time differenced dataset\n",
        "diff_moving_avg = moving_average_forecast(diff_series, 30)\n",
        "\n",
        "# Slice the prediction points that corresponds to the validation set time steps\n",
        "diff_moving_avg = diff_moving_avg[split_time - 365 - 30:]\n",
        "\n",
        "# Slice the ground truth points that corresponds to the validation set time steps\n",
        "diff_series = diff_series[split_time - 365:]\n",
        "\n",
        "# Plot the results\n",
        "plot_series(time_valid, (diff_series, diff_moving_avg))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gno9S2lyecnc"
      },
      "source": [
        "\n",
        "Теперь надо все вернуть"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:21:12.237797Z",
          "start_time": "2022-10-13T16:21:11.897744Z"
        },
        "id": "Dv6RWFq7TFGB"
      },
      "outputs": [],
      "source": [
        "# Add the trend and seasonality from the original series\n",
        "diff_moving_avg_plus_past = series[split_time - 365:-365] + diff_moving_avg\n",
        "\n",
        "# Plot the results\n",
        "plot_series(time_valid, (x_valid, diff_moving_avg_plus_past))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:21:47.912159Z",
          "start_time": "2022-10-13T16:21:47.890219Z"
        },
        "id": "59jmBrwcTFCx"
      },
      "outputs": [],
      "source": [
        "print(tf.keras.metrics.mse(x_valid, diff_moving_avg_plus_past).numpy())\n",
        "print(tf.keras.metrics.mae(x_valid, diff_moving_avg_plus_past).numpy())\n",
        "print(tf.keras.metrics.mape(x_valid, diff_moving_avg_plus_past).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYAa521hAeiC"
      },
      "source": [
        "Выглядит лучше наивного прогноза."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx9Et1Hkeusl"
      },
      "source": [
        "## Smoothing\n",
        "\n",
        "Надо следать за границами окон"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:23:25.054076Z",
          "start_time": "2022-10-13T16:23:24.630699Z"
        },
        "id": "K81dtROoTE_r"
      },
      "outputs": [],
      "source": [
        "# Smooth the original series before adding the time differenced moving average\n",
        "diff_moving_avg_plus_smooth_past = moving_average_forecast(series[split_time - 370:-359], 11) + diff_moving_avg\n",
        "\n",
        "# Plot the results\n",
        "plot_series(time_valid, (x_valid, diff_moving_avg_plus_smooth_past))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:24:37.445726Z",
          "start_time": "2022-10-13T16:24:37.417771Z"
        },
        "id": "iN2MsBxWTE3m"
      },
      "outputs": [],
      "source": [
        " # Compute the metrics\n",
        "print(tf.keras.metrics.mse(x_valid, diff_moving_avg_plus_smooth_past).numpy())\n",
        "print(tf.keras.metrics.mae(x_valid, diff_moving_avg_plus_smooth_past).numpy())\n",
        "print(tf.keras.metrics.mape(x_valid, diff_moving_avg_plus_smooth_past).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4LgMr4w2OqF"
      },
      "source": [
        "# One Layer NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:29:17.447642Z",
          "start_time": "2022-10-13T16:29:17.424705Z"
        },
        "id": "VpMSBa6h2OqF"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "window_size = 20\n",
        "batch_size = 32\n",
        "shuffle_buffer_size = 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:29:29.616626Z",
          "start_time": "2022-10-13T16:29:29.591725Z"
        },
        "id": "Zez5Oexx2OqF"
      },
      "outputs": [],
      "source": [
        "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
        "    \"\"\"Generates dataset windows\n",
        "\n",
        "    Args:\n",
        "      series (array of float) - contains the values of the time series\n",
        "      window_size (int) - the number of time steps to include in the feature\n",
        "      batch_size (int) - the batch size\n",
        "      shuffle_buffer(int) - buffer size to use for the shuffle method\n",
        "\n",
        "    Returns:\n",
        "      dataset (TF Dataset) - TF Dataset containing time windows\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate a TF Dataset from the series values\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
        "\n",
        "    # Window the data but only take those with the specified size\n",
        "    dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n",
        "\n",
        "    # Flatten the windows by putting its elements in a single batch\n",
        "    dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n",
        "\n",
        "    # Create tuples with features and labels\n",
        "    dataset = dataset.map(lambda window: (window[:-1], window[-1]))\n",
        "\n",
        "    # Shuffle the windows\n",
        "    dataset = dataset.shuffle(shuffle_buffer)\n",
        "\n",
        "    # Create batches of windows\n",
        "    dataset = dataset.batch(batch_size).prefetch(1)\n",
        "\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:29:31.419102Z",
          "start_time": "2022-10-13T16:29:31.161868Z"
        },
        "id": "Ygi-i_Gz2OqG"
      },
      "outputs": [],
      "source": [
        "# Generate the dataset windows\n",
        "dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:29:32.945541Z",
          "start_time": "2022-10-13T16:29:32.545606Z"
        },
        "id": "N_Edyk-c2OqG"
      },
      "outputs": [],
      "source": [
        "# Print properties of a single batch\n",
        "for windows in dataset.take(1):\n",
        "    print(f'data type: {type(windows)}')\n",
        "    print(f'number of elements in the tuple: {len(windows)}')\n",
        "    print(f'shape of first element: {windows[0].shape}')\n",
        "    print(f'shape of second element: {windows[1].shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1ldrzxA2OqG"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpzvzrzK2OqG"
      },
      "source": [
        "### Build"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:31:41.209373Z",
          "start_time": "2022-10-13T16:31:40.859792Z"
        },
        "id": "xtWBoM7m2OqG"
      },
      "outputs": [],
      "source": [
        "# Build the single layer neural network\n",
        "l0 = tf.keras.layers.Dense(1, input_shape=[window_size])\n",
        "model = tf.keras.models.Sequential([l0])\n",
        "\n",
        "# Print the initial layer weights\n",
        "print(\"Layer weights: \\n {} \\n\".format(l0.get_weights()))\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Is3QHj-t2OqG"
      },
      "source": [
        "### train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:32:14.216048Z",
          "start_time": "2022-10-13T16:32:14.179631Z"
        },
        "id": "E6krH9Gf2OqG"
      },
      "outputs": [],
      "source": [
        "# Set the training parameters\n",
        "model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.SGD(learning_rate=1e-6, momentum=0.9))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:33:27.852377Z",
          "start_time": "2022-10-13T16:32:40.280398Z"
        },
        "id": "y4Y6TWBa2OqG",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "model.fit(dataset,epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:33:30.968170Z",
          "start_time": "2022-10-13T16:33:30.947226Z"
        },
        "id": "4xhWJ6tG2OqG"
      },
      "outputs": [],
      "source": [
        "# Print the layer weights\n",
        "print(\"Layer weights {}\".format(l0.get_weights()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYtfhJ_X2OqG"
      },
      "source": [
        "### Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:33:37.658855Z",
          "start_time": "2022-10-13T16:33:37.307973Z"
        },
        "id": "8ORBEf4o2OqG"
      },
      "outputs": [],
      "source": [
        "# Shape of the first 20 data points slice\n",
        "print(f'shape of series[0:20]: {series[0:20].shape}')\n",
        "\n",
        "# Shape after adding a batch dimension\n",
        "print(f'shape of series[0:20][np.newaxis]: {series[0:20][np.newaxis].shape}')\n",
        "\n",
        "# Shape after adding a batch dimension (alternate way)\n",
        "print(f'shape of series[0:20][np.newaxis]: {np.expand_dims(series[0:20], axis=0).shape}')\n",
        "\n",
        "# Sample model prediction\n",
        "print(f'model prediction: {model.predict(series[0:20][np.newaxis])}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-11T14:33:29.586412Z",
          "start_time": "2022-10-11T14:30:38.900598Z"
        },
        "id": "o1i2idH72OqG",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Initialize a list\n",
        "forecast = []\n",
        "\n",
        "# Use the model to predict data points per window size\n",
        "for time in range(len(series) - window_size):\n",
        "    forecast.append(model.predict(series[time:time + window_size][np.newaxis]))\n",
        "\n",
        "# Slice the points that are aligned with the validation set\n",
        "forecast = forecast[split_time - window_size:]\n",
        "\n",
        "# Compare number of elements in the predictions and the validation set\n",
        "print(f'length of the forecast list: {len(forecast)}')\n",
        "print(f'shape of the validation set: {x_valid.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:34:48.300166Z",
          "start_time": "2022-10-13T16:34:48.282574Z"
        },
        "id": "6DwIy6q62OqG"
      },
      "outputs": [],
      "source": [
        "def model_forecast(model, series, window_size, batch_size):\n",
        "    \"\"\"Uses an input model to generate predictions on data windows\n",
        "\n",
        "    Args:\n",
        "      model (TF Keras Model) - model that accepts data windows\n",
        "      series (array of float) - contains the values of the time series\n",
        "      window_size (int) - the number of time steps to include in the window\n",
        "      batch_size (int) - the batch size\n",
        "\n",
        "    Returns:\n",
        "      forecast (numpy array) - array containing predictions\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate a TF Dataset from the series values\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
        "\n",
        "    # Window the data but only take those with the specified size\n",
        "    dataset = dataset.window(window_size, shift=1, drop_remainder=True)\n",
        "\n",
        "    # Flatten the windows by putting its elements in a single batch\n",
        "    dataset = dataset.flat_map(lambda w: w.batch(window_size))\n",
        "\n",
        "    # Create batches of windows\n",
        "    dataset = dataset.batch(batch_size).prefetch(1)\n",
        "\n",
        "    # Get predictions on the entire dataset\n",
        "    forecast = model.predict(dataset)\n",
        "\n",
        "    return forecast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:34:57.280200Z",
          "start_time": "2022-10-13T16:34:56.465510Z"
        },
        "id": "9ZuLU2AH2OqH"
      },
      "outputs": [],
      "source": [
        "# Reduce the original series\n",
        "forecast_series = series[split_time - window_size:-1]\n",
        "\n",
        "# Use helper function to generate predictions\n",
        "forecast = model_forecast(model, forecast_series, window_size, batch_size)\n",
        "\n",
        "# Drop single dimensional axis\n",
        "results = forecast.squeeze()\n",
        "\n",
        "# Plot the results\n",
        "plot_series(time_valid, (x_valid, results))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:35:09.301657Z",
          "start_time": "2022-10-13T16:35:09.283703Z"
        },
        "id": "HtanDZvc2OqH"
      },
      "outputs": [],
      "source": [
        "# Compute the metrics\n",
        "print(tf.keras.metrics.mse(x_valid, results).numpy())\n",
        "print(tf.keras.metrics.mae(x_valid, results).numpy())\n",
        "print(tf.keras.metrics.mape(x_valid, results).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efRNPzfe2OqH"
      },
      "source": [
        "# Deep NN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X13ip8JC2OqH"
      },
      "source": [
        "*Курсив*![title](/content/deepnn.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlWC8F7h2OqH"
      },
      "source": [
        "## Build"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:41:14.762324Z",
          "start_time": "2022-10-13T16:41:14.633671Z"
        },
        "id": "pynLHYm52OqH"
      },
      "outputs": [],
      "source": [
        "# Build the model\n",
        "model_baseline = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(10, input_shape=[window_size], activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(10, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Print the model summary\n",
        "model_baseline.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNA1Qqxe2OqH"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:41:17.437682Z",
          "start_time": "2022-10-13T16:41:17.416774Z"
        },
        "id": "yOeR84qk2OqH"
      },
      "outputs": [],
      "source": [
        "# Set the training parameters\n",
        "model_baseline.compile(loss=\"mse\", optimizer=tf.keras.optimizers.SGD(learning_rate=1e-6, momentum=0.9))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:42:19.543202Z",
          "start_time": "2022-10-13T16:41:19.364472Z"
        },
        "id": "uLC6J7K82OqH",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "model_baseline.fit(dataset,epochs=150)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKdjNpCc2OqH"
      },
      "source": [
        "## Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:42:59.364668Z",
          "start_time": "2022-10-13T16:42:58.645619Z"
        },
        "id": "A46NAtdQ2OqH"
      },
      "outputs": [],
      "source": [
        "# Reduce the original series\n",
        "forecast_series = series[split_time - window_size:-1]\n",
        "\n",
        "# Use helper function to generate predictions\n",
        "forecast = model_forecast(model_baseline, forecast_series, window_size, batch_size)\n",
        "\n",
        "# Drop single dimensional axis\n",
        "results = forecast.squeeze()\n",
        "\n",
        "# Plot the results\n",
        "plot_series(time_valid, (x_valid, results))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T10:53:41.324948Z",
          "start_time": "2022-10-13T10:53:36.984991Z"
        },
        "id": "o-7I_Xrq2OqH",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Initialize a list\n",
        "forecast = []\n",
        "\n",
        "# Reduce the original series\n",
        "forecast_series = series[split_time - window_size:]\n",
        "\n",
        "# Use the model to predict data points per window size\n",
        "for time in range(len(forecast_series) - window_size):\n",
        "    forecast.append(model_baseline.predict(forecast_series[time:time + window_size][np.newaxis]))\n",
        "\n",
        "# Convert to a numpy array and drop single dimensional axes\n",
        "results = np.array(forecast).squeeze()\n",
        "\n",
        "# Plot the results\n",
        "plot_series(time_valid, (x_valid, results))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:43:10.752878Z",
          "start_time": "2022-10-13T16:43:10.732935Z"
        },
        "id": "FPY2Ena72OqH"
      },
      "outputs": [],
      "source": [
        "# Compute the metrics\n",
        "print(tf.keras.metrics.mse(x_valid, results).numpy())\n",
        "print(tf.keras.metrics.mae(x_valid, results).numpy())\n",
        "print(tf.keras.metrics.mape(x_valid, results).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWzWJmVF2OqI"
      },
      "source": [
        "## Callback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:44:15.447000Z",
          "start_time": "2022-10-13T16:44:15.347266Z"
        },
        "id": "CIeVuI272OqI"
      },
      "outputs": [],
      "source": [
        "# Build the Model\n",
        "model_tune = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(10, input_shape=[window_size], activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(10, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:44:29.689072Z",
          "start_time": "2022-10-13T16:44:29.670079Z"
        },
        "id": "AVKN-ONE2OqI"
      },
      "outputs": [],
      "source": [
        "# Set the learning rate scheduler\n",
        "lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
        "    lambda epoch: 1e-6 * 10**(epoch / 20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:44:40.009484Z",
          "start_time": "2022-10-13T16:44:39.976540Z"
        },
        "id": "iZtMG1-f2OqI"
      },
      "outputs": [],
      "source": [
        "# Initialize the optimizer\n",
        "optimizer = tf.keras.optimizers.SGD(momentum=0.9)\n",
        "\n",
        "# Set the training parameters\n",
        "model_tune.compile(loss=\"mse\", optimizer=optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:45:49.303852Z",
          "start_time": "2022-10-13T16:45:03.795151Z"
        },
        "id": "HGtB6ycO2OqI",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "history = model_tune.fit(dataset, epochs=100, callbacks=[lr_schedule])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:46:01.197558Z",
          "start_time": "2022-10-13T16:46:00.156055Z"
        },
        "id": "IXQfh--Z2OqI"
      },
      "outputs": [],
      "source": [
        "# Define the learning rate array\n",
        "lrs = 1e-6 * (10 ** (np.arange(100) / 20))\n",
        "\n",
        "# Set the figure size\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Set the grid\n",
        "plt.grid(True)\n",
        "\n",
        "# Plot the loss in log scale\n",
        "plt.semilogx(lrs, history.history[\"loss\"])\n",
        "\n",
        "# Increase the tickmarks size\n",
        "plt.tick_params('both', length=10, width=1, which='both')\n",
        "\n",
        "# Set the plot boundaries\n",
        "plt.axis([1e-8, 1e-3, 0, 300])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:49:41.307123Z",
          "start_time": "2022-10-13T16:49:41.204399Z"
        },
        "id": "NPh4XMDu2OqI"
      },
      "outputs": [],
      "source": [
        "# Build the model\n",
        "model_tune = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(10, activation=\"relu\", input_shape=[window_size]),\n",
        "  tf.keras.layers.Dense(10, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:49:41.649210Z",
          "start_time": "2022-10-13T16:49:41.628266Z"
        },
        "id": "bnh9cxIW2OqI"
      },
      "outputs": [],
      "source": [
        "# Set the optimizer with the tuned learning rate\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=5e-6, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:50:29.248673Z",
          "start_time": "2022-10-13T16:49:41.999924Z"
        },
        "id": "47ZyZP-y2OqI",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Set the training parameters\n",
        "model_tune.compile(loss=\"mse\", optimizer=optimizer)\n",
        "\n",
        "# Train the model\n",
        "history = model_tune.fit(dataset, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:50:32.400364Z",
          "start_time": "2022-10-13T16:50:31.996448Z"
        },
        "id": "ngLGi2in2OqI"
      },
      "outputs": [],
      "source": [
        "# Plot the loss\n",
        "loss = history.history['loss']\n",
        "epochs = range(len(loss))\n",
        "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:50:37.463356Z",
          "start_time": "2022-10-13T16:50:37.161165Z"
        },
        "id": "dmHTGaEg2OqI"
      },
      "outputs": [],
      "source": [
        "# Plot all but the first 10\n",
        "loss = history.history['loss']\n",
        "epochs = range(10, len(loss))\n",
        "plot_loss = loss[10:]\n",
        "plt.plot(epochs, plot_loss, 'b', label='Training Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:51:58.527988Z",
          "start_time": "2022-10-13T16:51:57.844814Z"
        },
        "id": "ubbkS6iO2OqI",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Reduce the original series\n",
        "forecast_series = series[split_time - window_size:-1]\n",
        "\n",
        "# Use helper function to generate predictions\n",
        "forecast = model_forecast(model_tune, forecast_series, window_size, batch_size)\n",
        "\n",
        "# Drop single dimensional axis\n",
        "results = forecast.squeeze()\n",
        "\n",
        "# Plot the results\n",
        "plot_series(time_valid, (x_valid, results))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:52:04.736455Z",
          "start_time": "2022-10-13T16:52:04.707530Z"
        },
        "id": "5y8-4tbZ2OqI"
      },
      "outputs": [],
      "source": [
        "# Compute the metrics\n",
        "print(tf.keras.metrics.mse(x_valid, results).numpy())\n",
        "print(tf.keras.metrics.mae(x_valid, results).numpy())\n",
        "print(tf.keras.metrics.mape(x_valid, results).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DgC4J4T2OqI"
      },
      "source": [
        "# RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYVHr3rj2OqI"
      },
      "source": [
        "![title](rnn1.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:56:00.146418Z",
          "start_time": "2022-10-13T16:55:57.052163Z"
        },
        "id": "OC8mw4h-2OqJ"
      },
      "outputs": [],
      "source": [
        "def step_series(n, mean, scale, n_steps):\n",
        "    s = np.zeros(n)\n",
        "    step_idx = np.random.randint(0, n, n_steps)\n",
        "    value = mean\n",
        "    for t in range(n):\n",
        "        s[t] = value\n",
        "        if t in step_idx:\n",
        "            value = mean + scale * np.random.randn()\n",
        "    return s\n",
        "\n",
        "def linear_link(x):\n",
        "    return x\n",
        "\n",
        "def mem_link(x, length = 50):\n",
        "    mfilter = np.exp(np.linspace(-10, 0, length))\n",
        "    return np.convolve(x, mfilter/np.sum(mfilter), mode='same')\n",
        "\n",
        "def create_signal(links = [linear_link, mem_link]):\n",
        "    days_year = 365\n",
        "    quaters_year = 4\n",
        "    days_week = 7\n",
        "\n",
        "    # three years of data, daily resolution\n",
        "    idx = pd.date_range(start='2018-01-01', end='2021-01-01', freq='D')\n",
        "\n",
        "    df = pd.DataFrame(index=idx, dtype=float)\n",
        "    df = df.fillna(0.0)\n",
        "\n",
        "    n = len(df.index)\n",
        "    trend = np.zeros(n)\n",
        "    seasonality = np.zeros(n)\n",
        "    for t in range(n):\n",
        "        trend[t] = 2.0 * t/n\n",
        "        seasonality[t] = 4.0 * np.sin(np.pi * t/days_year*quaters_year)\n",
        "\n",
        "    covariates = [step_series(n, 0, 1.0, 80), step_series(n, 0, 1.0, 80)]\n",
        "    covariate_links = [ links[i](covariates[i]) for i in range(2) ]\n",
        "\n",
        "    noise = 0.5 * np.random.randn(n)\n",
        "\n",
        "    signal = trend + seasonality + np.sum(covariate_links, axis=0) + noise\n",
        "\n",
        "    df['signal'], df['trend'], df['seasonality'], df['noise'] = signal, trend, seasonality, noise\n",
        "    for i in range(2):\n",
        "        df[f'covariate_0{i+1}'] = covariates[i]\n",
        "        df[f'covariate_0{i+1}_link'] = covariate_links[i]\n",
        "\n",
        "    return df\n",
        "\n",
        "df = create_signal()\n",
        "fig, ax = plt.subplots(len(df.columns[:]), figsize=(20, 15))\n",
        "for i, c in enumerate(df.columns[:]):\n",
        "    ax[i].plot(df.index, df[c])\n",
        "    ax[i].set_title(c)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:56:21.713224Z",
          "start_time": "2022-10-13T16:56:21.685298Z"
        },
        "id": "wbFgOCe22OqJ"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# train-test split and adjustments\n",
        "#\n",
        "def train_test_split(df, train_ratio, forecast_days_ahead, n_time_steps, time_step_interval):\n",
        "\n",
        "    # lenght of the input time window for each sample (the offset of the oldest sample in the input)\n",
        "    input_window_size = n_time_steps*time_step_interval\n",
        "\n",
        "    split_t = int(len(df)*train_ratio)\n",
        "    x_train, y_train = [], []\n",
        "    x_test, y_test = [], []\n",
        "    y_col_idx = list(df.columns).index('signal')\n",
        "    for i in range(input_window_size, len(df)):\n",
        "        t_start = df.index[i - input_window_size]\n",
        "        t_end = df.index[i]\n",
        "        # we zero out last forecast_days_ahead signal observations, but covariates are assumed to be known\n",
        "        x_t = df[t_start:t_end:time_step_interval].values.copy()\n",
        "        if time_step_interval <= forecast_days_ahead:\n",
        "            x_t[-int((forecast_days_ahead) / time_step_interval):, y_col_idx] = 0\n",
        "\n",
        "        y_t = df.iloc[i]['signal']\n",
        "\n",
        "        if i < split_t:\n",
        "            x_train.append(x_t)\n",
        "            y_train.append(y_t)\n",
        "        else:\n",
        "            x_test.append(x_t)\n",
        "            y_test.append(y_t)\n",
        "\n",
        "    return np.stack(x_train), np.hstack(y_train), np.stack(x_test), np.hstack(y_test)\n",
        "\n",
        "\n",
        "#\n",
        "# engineer features and create input tensors\n",
        "#\n",
        "def prepare_features(df):\n",
        "    df_prep = df[['signal', 'covariate_01', 'covariate_02']]\n",
        "    df_prep['year'] = df_prep.index.year\n",
        "    df_prep['month'] = df_prep.index.month\n",
        "    df_prep['day_of_year'] = df_prep.index.dayofyear\n",
        "\n",
        "    def normalize(df):\n",
        "        x = df.values\n",
        "        min_max_scaler = MinMaxScaler()\n",
        "        x_scaled = min_max_scaler.fit_transform(x)\n",
        "        return pd.DataFrame(x_scaled, index=df.index, columns=df.columns)\n",
        "\n",
        "    return normalize(df_prep)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:57:10.637414Z",
          "start_time": "2022-10-13T16:57:09.873830Z"
        },
        "id": "b0iERVyr2OqJ"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# parameters\n",
        "#\n",
        "n_time_steps = 40         # lenght of LSTM input in samples\n",
        "time_step_interval = 2    # sampling interval, days\n",
        "hidden_units = 8          # LSTM state dimensionality\n",
        "forecast_days_ahead = 7\n",
        "train_ratio = 0.8\n",
        "\n",
        "#\n",
        "# generate data and fit the model\n",
        "#\n",
        "# df = create_signal()\n",
        "df_prep = prepare_features(df)\n",
        "x_train, y_train, x_test, y_test = train_test_split(df_prep,\n",
        "                                                    train_ratio,\n",
        "                                                    forecast_days_ahead,\n",
        "                                                    n_time_steps,\n",
        "                                                    time_step_interval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:58:29.259516Z",
          "start_time": "2022-10-13T16:58:29.210647Z"
        },
        "id": "kQKAO71C2OqJ",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "df_prep.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66wvaaq42OqJ"
      },
      "source": [
        "## Build"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:59:17.038365Z",
          "start_time": "2022-10-13T16:59:17.019380Z"
        },
        "id": "ME1M9mhG2OqJ"
      },
      "outputs": [],
      "source": [
        "n_samples = x_train.shape[0]\n",
        "n_features = x_train.shape[2]\n",
        "\n",
        "input_shape=(n_time_steps, n_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T16:59:19.514933Z",
          "start_time": "2022-10-13T16:59:19.491001Z"
        },
        "id": "TkexS0G22OqJ"
      },
      "outputs": [],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T17:00:27.618312Z",
          "start_time": "2022-10-13T17:00:27.206410Z"
        },
        "id": "a6Fj06rR2OqJ"
      },
      "outputs": [],
      "source": [
        "# Build the Model\n",
        "model_tune = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.InputLayer(input_shape=(x_train.shape[1], n_features)),\n",
        "    tf.keras.layers.SimpleRNN(units=10, return_sequences=True),\n",
        "    tf.keras.layers.SimpleRNN(10),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Print the model summary\n",
        "model_tune.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYzXkOys2OqJ"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T17:03:17.964287Z",
          "start_time": "2022-10-13T17:00:59.612640Z"
        },
        "id": "nakDyZh42OqJ",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Set the training parameters\n",
        "model_tune.compile(loss=tf.keras.losses.Huber(),\n",
        "              optimizer='RMSprop',\n",
        "              metrics=[\"mean_absolute_percentage_error\"])\n",
        "\n",
        "# Train the model\n",
        "history = model_tune.fit(x_train, y_train, epochs=20, batch_size=4, validation_data=(x_test, y_test),\n",
        "                    # use_multiprocessing=True,\n",
        "                         verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T17:03:21.490518Z",
          "start_time": "2022-10-13T17:03:20.579492Z"
        },
        "id": "bJTAAgMP2OqJ"
      },
      "outputs": [],
      "source": [
        "score = model_tune.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test MAPE:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMdW2fKw2OqJ"
      },
      "source": [
        "## Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T17:03:33.922509Z",
          "start_time": "2022-10-13T17:03:32.340442Z"
        },
        "id": "JvPXmxF52OqK"
      },
      "outputs": [],
      "source": [
        "input_window_size = n_time_steps*time_step_interval\n",
        "x = np.vstack([x_train, x_test])\n",
        "y_hat = model_tune.predict(x)\n",
        "forecast = np.append(np.zeros(input_window_size), y_hat)\n",
        "\n",
        "#\n",
        "# plot the forecast\n",
        "#\n",
        "fig, ax = plt.subplots(1, figsize=(20, 5))\n",
        "ax.plot(df_prep.index, forecast, label=f'Forecast ({forecast_days_ahead} days ahead)')\n",
        "ax.plot(df_prep.index, df_prep['signal'], label='Signal')\n",
        "ax.axvline(x=df.index[int(len(df) * train_ratio)], linestyle='--')\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALuvKjp22OqK"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxYroGiw2OqK"
      },
      "source": [
        "![title](lstm2.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBK_8oN12OqK"
      },
      "source": [
        "## Build"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T17:06:06.138047Z",
          "start_time": "2022-10-13T17:06:03.156389Z"
        },
        "id": "RPbnaSud2OqK"
      },
      "outputs": [],
      "source": [
        "# Build the Model\n",
        "model_tune = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.InputLayer(input_shape=(x_train.shape[1], n_features)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(10, return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(10)),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Print the model summary\n",
        "model_tune.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9rPPSxo2OqK"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T17:14:08.270029Z",
          "start_time": "2022-10-13T17:09:10.059653Z"
        },
        "id": "DLjIIjvM2OqK",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Set the training parameters\n",
        "model_tune.compile(loss=tf.keras.losses.Huber(),\n",
        "              optimizer='RMSprop',\n",
        "              metrics=[\"mean_absolute_percentage_error\"])\n",
        "\n",
        "# Train the model\n",
        "history = model_tune.fit(x_train, y_train, epochs=20, batch_size=4, validation_data=(x_test, y_test),\n",
        "                    # use_multiprocessing=True,\n",
        "                         verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T17:14:14.694702Z",
          "start_time": "2022-10-13T17:14:11.010721Z"
        },
        "id": "bamSJmmf2OqK"
      },
      "outputs": [],
      "source": [
        "score = model_tune.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test MAPE:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTF_rDXf2OqK"
      },
      "source": [
        "## Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T17:14:29.426425Z",
          "start_time": "2022-10-13T17:14:24.778295Z"
        },
        "id": "ZItO1SPQ2OqK"
      },
      "outputs": [],
      "source": [
        "input_window_size = n_time_steps*time_step_interval\n",
        "x = np.vstack([x_train, x_test])\n",
        "y_hat = model_tune.predict(x)\n",
        "forecast = np.append(np.zeros(input_window_size), y_hat)\n",
        "\n",
        "#\n",
        "# plot the forecast\n",
        "#\n",
        "fig, ax = plt.subplots(1, figsize=(20, 5))\n",
        "ax.plot(df_prep.index, forecast, label=f'Forecast ({forecast_days_ahead} days ahead)')\n",
        "ax.plot(df_prep.index, df_prep['signal'], label='Signal')\n",
        "ax.axvline(x=df.index[int(len(df) * train_ratio)], linestyle='--')\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRYaHu0_2OqK"
      },
      "source": [
        "# LSTM II"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hGkpwdB2OqK"
      },
      "source": [
        "## Build"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T13:39:08.707748Z",
          "start_time": "2022-10-13T13:37:04.398927Z"
        },
        "id": "2CYExVDh2OqK",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "input_model = tf.keras.layers.Input(shape=(x_train.shape[1], n_features))\n",
        "lstm_state_seq, state_h, state_c = tf.keras.layers.LSTM(10, return_sequences=True, return_state=True)(input_model)\n",
        "output_dense = tf.keras.layers.Dense(1)(state_c)\n",
        "model_lstm = tf.keras.models.Model(inputs=input_model, outputs=output_dense)\n",
        "\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "model_lstm.compile(loss=tf.keras.losses.Huber(),\n",
        "              optimizer='RMSprop',\n",
        "              metrics=[\"mean_absolute_percentage_error\"])\n",
        "model_lstm.summary()\n",
        "model_lstm.fit(x_train, y_train, epochs=20, batch_size=4,\n",
        "               validation_data=(x_test, y_test),\n",
        "            #    use_multiprocessing=True,\n",
        "               verbose=1)\n",
        "score = model_lstm.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test MAPE:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXzDs7aM2OqK"
      },
      "source": [
        "## Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T13:39:09.858361Z",
          "start_time": "2022-10-13T13:39:08.713702Z"
        },
        "id": "FnH2mXWv2OqK"
      },
      "outputs": [],
      "source": [
        "## input_window_size = n_time_steps*time_step_interval\n",
        "x = np.vstack([x_train, x_test])\n",
        "y_hat = model_tune.predict(x)\n",
        "forecast = np.append(np.zeros(input_window_size), y_hat)\n",
        "\n",
        "#\n",
        "# plot the forecast\n",
        "#\n",
        "fig, ax = plt.subplots(1, figsize=(20, 5))\n",
        "ax.plot(df_prep.index, forecast, label=f'Forecast ({forecast_days_ahead} days ahead)')\n",
        "ax.plot(df_prep.index, df_prep['signal'], label='Signal')\n",
        "ax.axvline(x=df.index[int(len(df) * train_ratio)], linestyle='--')\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcRvDhCT2OqL"
      },
      "source": [
        "## State"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T13:41:35.488788Z",
          "start_time": "2022-10-13T13:41:30.008877Z"
        },
        "id": "TssZv99N2OqL"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# plot the evolution of the LSTM state\n",
        "#\n",
        "lstm_state_tap = tf.keras.models.Model(model_lstm.input, lstm_state_seq)\n",
        "lstm_state_trace = lstm_state_tap.predict(x)\n",
        "\n",
        "state_series = lstm_state_trace[:, -1, :].T\n",
        "fig, ax = plt.subplots(len(state_series), figsize=(20, 15))\n",
        "for i, state in enumerate(state_series):\n",
        "    ax[i].plot(df_prep.index[:len(state)], state, label=f'State dimension {i}')\n",
        "    for j in [1, 2]:\n",
        "        ax[i].plot(df_prep.index[:len(state)], df_prep[f'covariate_0{j}'][:len(state)], color='#bbbbbb', label=f'Covariate 0{j}')\n",
        "\n",
        "    ax[i].legend(loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sbs7M_M2OqL"
      },
      "source": [
        "# GBDT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWcy-5Lg2OqL"
      },
      "source": [
        "## update methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T17:17:42.810129Z",
          "start_time": "2022-10-13T17:17:42.780178Z"
        },
        "id": "eT7dIvUE2OqL"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# engineer features for the model\n",
        "#\n",
        "def features_regression(df):\n",
        "    observed_features = ['covariate_01', 'covariate_02']\n",
        "    dff = df[['signal'] + observed_features]\n",
        "\n",
        "    dff['year'] = dff.index.year\n",
        "    dff['month'] = dff.index.month\n",
        "    dff['day_of_year'] = dff.index.dayofyear\n",
        "\n",
        "    feature_lags = [7, 14, 21, 28, 35, 42, 49, 120, 182, 365]\n",
        "    for lag in feature_lags:\n",
        "        dff.loc[:, f'signal_lag_{lag}'] = dff['signal'].shift(periods=lag, fill_value=0).values\n",
        "\n",
        "    return dff\n",
        "\n",
        "\n",
        "#\n",
        "# train-test split\n",
        "#\n",
        "def split_train_test(df, train_ratio):\n",
        "    y_train, y_test = [], []\n",
        "    x_train, x_test = [], []\n",
        "    split_t = int(len(df)*train_ratio)\n",
        "\n",
        "    y = df['signal']\n",
        "    y_train = y[:split_t]\n",
        "    y_test = y[split_t:]\n",
        "\n",
        "    xdf = df.drop('signal', inplace=False, axis=1)\n",
        "    x_train = xdf[:split_t]\n",
        "    x_test = xdf[split_t:]\n",
        "\n",
        "    return x_train, y_train, x_test, y_test\n",
        "\n",
        "#\n",
        "# fit LightGBM model\n",
        "#\n",
        "def fit_lightgbm(x_train, y_train, x_test, y_test, n_estimators=100, verbose_eval=50):\n",
        "\n",
        "    model = lightgbm.LGBMRegressor(\n",
        "        boosting_type = 'gbdt',\n",
        "        #num_leaves = 8 - 1,\n",
        "        n_estimators=n_estimators)\n",
        "\n",
        "    model.fit(x_train,\n",
        "              y_train,\n",
        "              eval_set=[(x_train, y_train), (x_test, y_test)],\n",
        "              eval_metric='mape',\n",
        "            #   verbose=verbose_eval\n",
        "              )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T17:18:28.117809Z",
          "start_time": "2022-10-13T17:18:23.747667Z"
        },
        "id": "vG-pFfeK2OqL"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# generate data sample and fit the model\n",
        "#\n",
        "# df = features_regression(create_signal(links = [linear_link, mem_link]))\n",
        "df_gbdt = features_regression(df)\n",
        "train_ratio = 0.8\n",
        "x_train, y_train, x_test, y_test = split_train_test(df_gbdt, train_ratio)\n",
        "model = fit_lightgbm(x_train, y_train, x_test, y_test, n_estimators=500)    # can use fit_xgboost as an alternative\n",
        "\n",
        "#\n",
        "# plot the fitting metrics\n",
        "#\n",
        "lightgbm.plot_metric(model, metric='mape', figsize=(10, 3))\n",
        "\n",
        "#\n",
        "# plot the forecast\n",
        "#\n",
        "forecast = model.predict(pd.concat([x_train, x_test]))\n",
        "\n",
        "fig, ax = plt.subplots(1, figsize=(20, 5))\n",
        "ax.plot(df_gbdt.index, forecast, label='Forecast (7 days ahead)')\n",
        "ax.plot(df_gbdt.index, df_gbdt['signal'], label='Actuals')\n",
        "ax.axvline(x=df.index[int(len(df_gbdt) * train_ratio)], linestyle='--')\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBuMvkXT2OqL"
      },
      "source": [
        "## Estimate Confidence Intervals for the Forecast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T17:45:06.096011Z",
          "start_time": "2022-10-13T17:45:03.108260Z"
        },
        "id": "ksY25TcX2OqL"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# fit the quantile regression model with LightGBM\n",
        "#\n",
        "def fit_lightgbm_quantile(x_train, y_train, x_test, y_test, alpha, n_estimators=100, verbose_eval=50):\n",
        "\n",
        "    model = lightgbm.LGBMRegressor(\n",
        "        boosting_type = 'gbdt',\n",
        "        objective = 'quantile',\n",
        "        alpha = alpha,\n",
        "        num_leaves = 8 - 1,\n",
        "        n_estimators=n_estimators)\n",
        "\n",
        "    model.fit(x_train,\n",
        "              y_train,\n",
        "              eval_set=[(x_train, y_train), (x_test, y_test)],\n",
        "              eval_metric='mape',\n",
        "            #   verbose=verbose_eval\n",
        "              )\n",
        "\n",
        "    return model\n",
        "\n",
        "#\n",
        "# generate data sample and fit models\n",
        "#\n",
        "df = features_regression(create_signal(links = [linear_link, mem_link]))\n",
        "train_ratio = 0.8\n",
        "x_train, y_train, x_test, y_test = split_train_test(df, train_ratio)\n",
        "alphas = [0.90, 0.80, 0.70, 0.60]\n",
        "model_mean = fit_lightgbm(x_train, y_train, x_test, y_test)\n",
        "models_upper = [fit_lightgbm_quantile(x_train, y_train, x_test, y_test, 1 - alpha, verbose_eval=0) for alpha in alphas]\n",
        "models_lower = [fit_lightgbm_quantile(x_train, y_train, x_test, y_test, alpha, verbose_eval=0) for alpha in alphas]\n",
        "\n",
        "#\n",
        "# plot the forecasts\n",
        "#\n",
        "x = pd.concat([x_train, x_test])\n",
        "forecasts_upper = [model.predict(x) for model in models_upper]\n",
        "forecasts_lower = [model.predict(x) for model in models_lower]\n",
        "forecast_mean = model_mean.predict(x)\n",
        "\n",
        "fig, ax = plt.subplots(1, figsize=(20, 5))\n",
        "pal = [\"#eeef20\", \"#d4d700\", \"#80b918\", \"#2b9348\"]\n",
        "for i, alpha in enumerate(alphas):\n",
        "    ax.fill_between(df.index, forecasts_lower[i], forecasts_upper[i], alpha=0.5, fc=pal[i], ec='None', label=f'Forecast CI ({alpha})')\n",
        "ax.plot(df.index, df['signal'], color='r', alpha=0.2, label='Actuals')\n",
        "ax.plot(df.index, forecast_mean, color='k', alpha=0.5, label='Forecast mean')\n",
        "ax.axvline(x=df.index[int(len(df) * train_ratio)], linestyle='--')\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvZN6HwG2OqL"
      },
      "source": [
        "# Как улучшить GBDT?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lh_y_RatSpT1"
      },
      "outputs": [],
      "source": [
        "df['signal_orig'] = df.signal.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T17:53:58.339959Z",
          "start_time": "2022-10-13T17:53:57.854162Z"
        },
        "id": "2QgoVv3G2OqL"
      },
      "outputs": [],
      "source": [
        "plt.plot(df.signal_orig.diff())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T17:57:08.174016Z",
          "start_time": "2022-10-13T17:57:07.703274Z"
        },
        "id": "UUj69YCK2OqL"
      },
      "outputs": [],
      "source": [
        "df.signal.hist(bins='auto')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucGQ7z4k2OqM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQWmKUff2OqM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLEMz94-2OqM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T17:45:59.947465Z",
          "start_time": "2022-10-13T17:45:59.926517Z"
        },
        "id": "5lKtlxcr2OqM"
      },
      "outputs": [],
      "source": [
        "def preprocessing_for_gbdt(df):\n",
        "    df['signal_orig'] = df.signal.copy()\n",
        "    df['signal'] = df.signal_orig.diff()\n",
        "\n",
        "def features_regression_best(df):\n",
        "    observed_features = ['covariate_01', 'covariate_02']\n",
        "    dff = df[['signal'] + observed_features]\n",
        "\n",
        "    dff['year'] = dff.index.year\n",
        "    dff['month'] = dff.index.month\n",
        "    dff['day_of_year'] = dff.index.dayofyear\n",
        "\n",
        "    feature_lags = [7, 14, 21, 28, 35, 42, 49, 120, 182, 365]\n",
        "    for lag in feature_lags:\n",
        "        dff.loc[:, f'signal_lag_{lag}'] = dff['signal'].shift(periods=lag, fill_value=0).values\n",
        "\n",
        "\n",
        "    return dff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T17:46:09.258499Z",
          "start_time": "2022-10-13T17:46:09.206637Z"
        },
        "id": "GGLXk7Js2OqM"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T17:46:23.202889Z",
          "start_time": "2022-10-13T17:46:17.836837Z"
        },
        "id": "yEVDOMqS2OqM",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "preprocessing_for_gbdt(df)\n",
        "df_gbdt = features_regression_best(df)\n",
        "train_ratio = 0.8\n",
        "x_train, y_train, x_test, y_test = split_train_test(df_gbdt, train_ratio)\n",
        "model = fit_lightgbm(x_train, y_train, x_test, y_test, n_estimators=500)    # can use fit_xgboost as an alternative\n",
        "\n",
        "#\n",
        "# plot the fitting metrics\n",
        "#\n",
        "lightgbm.plot_metric(model, metric='mape', figsize=(10, 3))\n",
        "\n",
        "#\n",
        "# plot the forecast\n",
        "#\n",
        "forecast = model.predict(pd.concat([x_train, x_test]))\n",
        "\n",
        "fig, ax = plt.subplots(1, figsize=(20, 5))\n",
        "ax.plot(df_gbdt.index, forecast, label='Forecast (7 days ahead)')\n",
        "ax.plot(df_gbdt.index, df_gbdt['signal'], label='Actuals')\n",
        "ax.axvline(x=df.index[int(len(df_gbdt) * train_ratio)], linestyle='--')\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T17:46:32.390826Z",
          "start_time": "2022-10-13T17:46:32.380817Z"
        },
        "id": "WQxAydYx2OqM"
      },
      "outputs": [],
      "source": [
        "forecast_upd = forecast + df.signal_orig.shift()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T17:46:32.890454Z",
          "start_time": "2022-10-13T17:46:32.860537Z"
        },
        "id": "fMq_Yn882OqM"
      },
      "outputs": [],
      "source": [
        "forecast_upd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T17:46:38.362619Z",
          "start_time": "2022-10-13T17:46:37.810091Z"
        },
        "id": "GVOAYAiw2OqM"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, figsize=(20, 5))\n",
        "ax.plot(df_gbdt.index, forecast_upd, label='Forecast (7 days ahead)')\n",
        "ax.plot(df_gbdt.index, df['signal_orig'], label='Actuals')\n",
        "ax.axvline(x=df.index[int(len(df_gbdt) * train_ratio)], linestyle='--')\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T17:48:38.579090Z",
          "start_time": "2022-10-13T17:48:38.518248Z"
        },
        "id": "_XY0PkIi2OqM"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1do2-9N2OqM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T17:50:45.519996Z",
          "start_time": "2022-10-13T17:50:45.488082Z"
        },
        "id": "MKmZXd1i2OqM"
      },
      "outputs": [],
      "source": [
        "y_hat = model.predict(x_test) + df.signal_orig.iloc[-y_test.shape[0]:].shift()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T17:50:47.850463Z",
          "start_time": "2022-10-13T17:50:47.430621Z"
        },
        "id": "FL29VsdE2OqM"
      },
      "outputs": [],
      "source": [
        "plt.plot(y_hat)\n",
        "plt.plot(df.signal_orig.iloc[-y_test.shape[0]:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-13T17:52:37.398781Z",
          "start_time": "2022-10-13T17:52:37.379829Z"
        },
        "id": "2VSImNHN2OqM"
      },
      "outputs": [],
      "source": [
        "print(tf.keras.metrics.mean_absolute_percentage_error(df.signal_orig.iloc[-y_test.shape[0]+1:], y_hat[1:]).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_V96jpVDVkG5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIfA4iyjWRnN"
      },
      "source": [
        "# new data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JP9AIAMnWS72"
      },
      "outputs": [],
      "source": [
        "pip install ucimlrepo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWwOcmxnWTYn"
      },
      "outputs": [],
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "metro_interstate_traffic_volume = fetch_ucirepo(id=492)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = metro_interstate_traffic_volume.data.features\n",
        "X.date_time = pd.to_datetime(X.date_time)\n",
        "y = metro_interstate_traffic_volume.data.targets\n",
        "\n",
        "df = metro_interstate_traffic_volume.data.original\n",
        "df.date_time = pd.to_datetime(df.date_time)\n",
        "\n",
        "# metadata\n",
        "print(metro_interstate_traffic_volume.metadata)\n",
        "\n",
        "# variable information\n",
        "print(metro_interstate_traffic_volume.variables)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WN17qSdbWcnd"
      },
      "outputs": [],
      "source": [
        "y[:100].plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbcU3FhWWiwy"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ranf4MhBWnx4"
      },
      "outputs": [],
      "source": [
        "X_daily = df.assign(cur_date=pd.to_datetime(X.date_time.dt.date))\\\n",
        "    .groupby('cur_date')\\\n",
        "    .agg({'traffic_volume': 'sum'})\\\n",
        "    .reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsHsAEzjW0qR"
      },
      "outputs": [],
      "source": [
        "X_daily.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UISivCCTYI95"
      },
      "outputs": [],
      "source": [
        "X_daily.plot(figsize=(15, 5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smmOYq3Ra4GE"
      },
      "outputs": [],
      "source": [
        "X_daily.traffic_volume.describe(percentiles=[0.01, 0.5, 0.99])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tJCzv0kbOvm"
      },
      "outputs": [],
      "source": [
        "X_daily['traffic_volume_clipped'] = X_daily.traffic_volume.clip(lower=X_daily.traffic_volume.quantile(0.01))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdcDWqgObnnW"
      },
      "outputs": [],
      "source": [
        "X_daily.plot(figsize=(15, 5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_d--C8GYaaQ-"
      },
      "outputs": [],
      "source": [
        "X_daily.hist();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jm_nshc2agMt"
      },
      "outputs": [],
      "source": [
        "X_daily.traffic_volume.apply(np.log1p).plot(figsize=(15, 5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odZGgK2tbts_"
      },
      "outputs": [],
      "source": [
        "X_daily.traffic_volume_clipped.apply(np.log1p).plot(figsize=(15, 5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHgObuTfa1JT"
      },
      "outputs": [],
      "source": [
        "X_daily.traffic_volume.apply(np.log1p).hist();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLvOADSqb59B"
      },
      "outputs": [],
      "source": [
        "X_daily.traffic_volume_clipped.apply(np.log1p).hist();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lE2vRNJBZz7K"
      },
      "outputs": [],
      "source": [
        "def features_regression(df, feats=['traffic_volume_clipped']):\n",
        "    # observed_features = ['covariate_01', 'covariate_02']\n",
        "    # dff = df[['signal'] + observed_features]\n",
        "    dff = df.copy()\n",
        "\n",
        "    dff['year'] = dff.cur_date.dt.year\n",
        "    dff['month'] = dff.cur_date.dt.month\n",
        "    dff['day_of_year'] = dff.cur_date.dt.dayofyear\n",
        "\n",
        "    feature_lags = [7, 14, 21, 28, 35, 42, 49, 120, 182, 365]\n",
        "    for lag in feature_lags:\n",
        "        for feat in feats:\n",
        "            dff.loc[:, f'{feat}_{lag}'] = dff[feat].shift(periods=lag, fill_value=0).values\n",
        "\n",
        "    return dff\n",
        "\n",
        "\n",
        "#\n",
        "# train-test split\n",
        "#\n",
        "def split_train_test(df, train_ratio, target_col='traffic_volume_clipped', dt_col='cur_date'):\n",
        "    y_train, y_test = [], []\n",
        "    x_train, x_test = [], []\n",
        "    split_t = int(len(df)*train_ratio)\n",
        "\n",
        "    df = df.sort_values(dt_col)\n",
        "\n",
        "    y = df[target_col]\n",
        "    y_train = y[:split_t]\n",
        "    y_test = y[split_t:]\n",
        "\n",
        "    xdf = df.drop([target_col, dt_col], inplace=False, axis=1)\n",
        "    x_train = xdf[:split_t]\n",
        "    x_test = xdf[split_t:]\n",
        "\n",
        "    return x_train, y_train, x_test, y_test\n",
        "\n",
        "#\n",
        "# fit LightGBM model\n",
        "#\n",
        "def fit_lightgbm(x_train, y_train, x_test, y_test, n_estimators=100, verbose_eval=50):\n",
        "\n",
        "    model = lightgbm.LGBMRegressor(\n",
        "        boosting_type = 'gbdt',\n",
        "        #num_leaves = 8 - 1,\n",
        "        n_estimators=n_estimators)\n",
        "\n",
        "    model.fit(x_train,\n",
        "              y_train,\n",
        "              eval_set=[(x_train, y_train), (x_test, y_test)],\n",
        "              eval_metric='mape',\n",
        "            #   verbose=verbose_eval\n",
        "              )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8FTkL7ZePuV"
      },
      "outputs": [],
      "source": [
        "X_daily.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogEJqjmfaZow"
      },
      "outputs": [],
      "source": [
        "df_feats = features_regression(X_daily.drop(columns=['traffic_volume']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqQ8DkEYcoNV"
      },
      "outputs": [],
      "source": [
        "df_feats.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LySMAD67cw4Q"
      },
      "outputs": [],
      "source": [
        "train_ratio = 0.8\n",
        "x_train, y_train, x_test, y_test = split_train_test(df_feats, train_ratio)\n",
        "model = fit_lightgbm(x_train, y_train, x_test, y_test, n_estimators=500)    # can use fit_xgboost as an alternative\n",
        "\n",
        "#\n",
        "# plot the fitting metrics\n",
        "#\n",
        "lightgbm.plot_metric(model, metric='mape', figsize=(10, 3))\n",
        "\n",
        "#\n",
        "# plot the forecast\n",
        "#\n",
        "forecast = model.predict(pd.concat([x_train, x_test]))\n",
        "\n",
        "target_col = 'traffic_volume_clipped'\n",
        "\n",
        "fig, ax = plt.subplots(1, figsize=(20, 5))\n",
        "ax.plot(df_feats.index, forecast, label='Forecast (7 days ahead)')\n",
        "ax.plot(df_feats.index, df_feats[target_col], label='Actuals')\n",
        "ax.axvline(x=df.index[int(len(df_feats) * train_ratio)], linestyle='--')\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XqswwzBdclI"
      },
      "outputs": [],
      "source": [
        "target_col = 'traffic_volume_clipped'\n",
        "\n",
        "fig, ax = plt.subplots(1, figsize=(20, 5))\n",
        "ax.plot(df_feats.index[df.index[int(len(df_feats) * train_ratio)]:],\n",
        "                       forecast[df.index[int(len(df_feats) * train_ratio)]:],\n",
        "                       label='Forecast (7 days ahead)')\n",
        "ax.plot(df_feats.index[df.index[int(len(df_feats) * train_ratio)]:],\n",
        "        df_feats[target_col][df.index[int(len(df_feats) * train_ratio)]:],\n",
        "        label='Actuals')\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCksuBjqeC_3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVgMmXcae6M5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZdQtHJDin5f"
      },
      "source": [
        "# Online Retail II\n",
        "https://archive.ics.uci.edu/dataset/502/online+retail+ii\n",
        "\n",
        "InvoiceNo: Invoice number. Nominal. A 6-digit integral number uniquely assigned to each transaction. If this code starts with the letter 'c', it indicates a cancellation.\n",
        "\n",
        "StockCode: Product (item) code. Nominal. A 5-digit integral number uniquely assigned to each distinct product.\n",
        "\n",
        "Description: Product (item) name. Nominal.\n",
        "\n",
        "Quantity: The quantities of each product (item) per transaction. Numeric.\n",
        "\n",
        "InvoiceDate: Invice date and time. Numeric. The day and time when a transaction was generated.\n",
        "\n",
        "UnitPrice: Unit price. Numeric. Product price per unit in sterling (Â£).\n",
        "\n",
        "CustomerID: Customer number. Nominal. A 5-digit integral number uniquely assigned to each customer.\n",
        "\n",
        "Country: Country name. Nominal. The name of the country where a customer resides."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTE34s5MjSPN"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3n5ZoS9iqWm"
      },
      "outputs": [],
      "source": [
        "data = pd.read_excel('/content/online_retail_II.xlsx', header=0, engine='openpyxl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLkMhTuei0Kh"
      },
      "outputs": [],
      "source": [
        "data.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O27o-aXFjuhz"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-75H9HIrkFE8"
      },
      "outputs": [],
      "source": [
        "data.InvoiceDate = pd.to_datetime(data.InvoiceDate).dt.date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTKcGRhIkgxJ"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKgRIiuBkklm"
      },
      "outputs": [],
      "source": [
        "data['canceled'] = data.Invoice.apply(lambda x: str(x)[0] == 'c')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOafwOx4k8do"
      },
      "outputs": [],
      "source": [
        "data.canceled.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VaRMbK_olQaH"
      },
      "outputs": [],
      "source": [
        "data.groupby('StockCode').agg({'Description': 'nunique'}).sort_values('Description', ascending=False)[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loV-Tv6Ilbwa"
      },
      "outputs": [],
      "source": [
        "data.query(\"StockCode == 22734\")['Description'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqHZ_Rj7mUJ2"
      },
      "outputs": [],
      "source": [
        "data.Country.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmn8weAikiDD"
      },
      "outputs": [],
      "source": [
        "data_daily = data\\\n",
        "    .query(\"Country == 'United Kingdom'\")\\\n",
        "    .drop(columns=['Country'])\\\n",
        "    .groupby(['InvoiceDate', 'StockCode'])\\\n",
        "    .agg({'Quantity': 'sum',\n",
        "          'Price': 'mean'})\\\n",
        "    .reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBjViIRJmD5C"
      },
      "outputs": [],
      "source": [
        "data_daily.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAAzdHgtmFuG"
      },
      "outputs": [],
      "source": [
        "data_daily.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zt0aCg-1mG9-"
      },
      "outputs": [],
      "source": [
        "data_daily_stats = data_daily\\\n",
        "    .groupby('StockCode')\\\n",
        "    .agg({'InvoiceDate': ['min', 'max', 'nunique'],\n",
        "          'Quantity': ['min', 'max', 'mean', 'median'],\n",
        "          'Price': ['min', 'max', 'mean', 'median']})\\\n",
        "    .reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHXqVnBbmOe7"
      },
      "outputs": [],
      "source": [
        "data_daily_stats.sort_values(('InvoiceDate', 'nunique'), ascending=False).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhjH_5xjnEiJ"
      },
      "outputs": [],
      "source": [
        "(data_daily.InvoiceDate.max() - data_daily.InvoiceDate.min())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCr6kZuFnha7"
      },
      "outputs": [],
      "source": [
        "top_items = data_daily_stats\\\n",
        "    .sort_values(('InvoiceDate', 'nunique'), ascending=False)\\\n",
        "    .head()['StockCode'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSmhpz_fnwit"
      },
      "outputs": [],
      "source": [
        "top_items"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ecgX4CPnZCw"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "sns.lineplot(data=data_daily.query(\"StockCode in @top_items\"),\n",
        "                x='InvoiceDate',\n",
        "                y='Quantity',\n",
        "                hue='StockCode')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDgJWoIpoff7"
      },
      "outputs": [],
      "source": [
        "top_items"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VaeQYiwn6D5"
      },
      "outputs": [],
      "source": [
        "sns.lineplot(data=data_daily.query(\"StockCode == 21212\"),\n",
        "                x='InvoiceDate',\n",
        "                y='Quantity')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTXtSxiCW0At"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOsXZepjW0Xy"
      },
      "source": [
        "# ЗП"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEx1LO2OoXPd"
      },
      "outputs": [],
      "source": [
        "data_2019 = pd.read_excel('/content/tab2-zpl_01-2024.xlsx',\n",
        "                     engine='openpyxl',\n",
        "                     sheet_name=u'с 2019',\n",
        "                     header=[1, 2])\n",
        "data_2013 = pd.read_excel('/content/tab2-zpl_01-2024.xlsx',\n",
        "                     engine='openpyxl',\n",
        "                     sheet_name=u'2013-2018',\n",
        "                     header=[2, 3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPD05OkGVtzd"
      },
      "outputs": [],
      "source": [
        "data_2013.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-paxdkyhoOY"
      },
      "outputs": [],
      "source": [
        "data_2019.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YV90aBusWmJ4"
      },
      "outputs": [],
      "source": [
        "data_2013_xy = pd.DataFrame(data_2013.iloc[0, :].values[1:], columns=['inc'])\n",
        "data_2013_xy = data_2013_xy.set_index(pd.date_range(start='2013-01-01', end='2018-12-01', freq='MS'))\n",
        "\n",
        "data_2019_xy = pd.DataFrame(data_2019.iloc[0, :].values[1:], columns=['inc'])\n",
        "data_2019_xy = data_2019_xy.set_index(pd.date_range(start='2019-01-01', end='2024-01-01', freq='MS'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WkHNI0PiCuZ"
      },
      "outputs": [],
      "source": [
        "data_all = pd.concat((data_2013_xy, data_2019_xy), axis=0)\n",
        "data_all.index.name = 'month'\n",
        "data_all['inc'] = pd.to_numeric(data_all['inc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymNhwxpaXOd5"
      },
      "outputs": [],
      "source": [
        "data_all.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ea3yhUyOjcN_"
      },
      "outputs": [],
      "source": [
        "data_all.index.min(), data_all.index.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMN8p2-VkXG5"
      },
      "outputs": [],
      "source": [
        "data_all.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etassBd7W-Qk"
      },
      "source": [
        "## в лоб бустингом"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nssFA5SwXANn"
      },
      "outputs": [],
      "source": [
        "def features_regression(df, target_col, covariates_list=None):\n",
        "\n",
        "    observed_features = covariates_list\n",
        "    if observed_features:\n",
        "        dff = df[[target_col] + observed_features]\n",
        "    else:\n",
        "        dff = df[[target_col]]\n",
        "\n",
        "    dff['year'] = dff.index.year\n",
        "    dff['month'] = dff.index.month\n",
        "    dff['day_of_year'] = dff.index.dayofyear\n",
        "\n",
        "    feature_lags = [1, 2, 3, 6, 9, 12]\n",
        "    for lag in feature_lags:\n",
        "        dff.loc[:, f'{target_col}_lag_{lag}'] = dff[target_col].shift(periods=lag, fill_value=0).values\n",
        "\n",
        "    return dff\n",
        "\n",
        "\n",
        "#\n",
        "# train-test split\n",
        "#\n",
        "def split_train_test(df, train_ratio, target_col):\n",
        "    y_train, y_test = [], []\n",
        "    x_train, x_test = [], []\n",
        "    split_t = int(len(df)*train_ratio)\n",
        "\n",
        "    y = df[target_col]\n",
        "    y_train = y[:split_t]\n",
        "    y_test = y[split_t:]\n",
        "\n",
        "    xdf = df.drop(target_col, inplace=False, axis=1)\n",
        "    x_train = xdf[:split_t]\n",
        "    x_test = xdf[split_t:]\n",
        "\n",
        "    return x_train, y_train, x_test, y_test\n",
        "\n",
        "#\n",
        "# fit LightGBM model\n",
        "#\n",
        "def fit_lightgbm(x_train, y_train, x_test=None, y_test=None, n_estimators=100, verbose_eval=50):\n",
        "\n",
        "    model = lightgbm.LGBMRegressor(\n",
        "        boosting_type = 'gbdt',\n",
        "        #num_leaves = 8 - 1,\n",
        "        n_estimators=n_estimators,\n",
        "        verbose=-1\n",
        "        )\n",
        "    try:\n",
        "        model.fit(x_train,\n",
        "                y_train,\n",
        "                eval_set=[(x_train, y_train), (x_test, y_test)],\n",
        "                eval_metric='mape',\n",
        "                )\n",
        "    except:\n",
        "        model.fit(x_train,\n",
        "                y_train)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IvL_MB36uNrY"
      },
      "outputs": [],
      "source": [
        "df_gbdt = features_regression(data_all, target_col='inc')\n",
        "train_ratio = 0.8\n",
        "x_train, y_train, x_test, y_test = split_train_test(df_gbdt, train_ratio, target_col='inc')\n",
        "model = fit_lightgbm(x_train, y_train, x_test, y_test, n_estimators=500)    # can use fit_xgboost as an alternative\n",
        "\n",
        "#\n",
        "# plot the fitting metrics\n",
        "#\n",
        "lightgbm.plot_metric(model, metric='mape', figsize=(10, 3))\n",
        "\n",
        "#\n",
        "# plot the forecast\n",
        "#\n",
        "forecast = model.predict(pd.concat([x_train, x_test]))\n",
        "\n",
        "fig, ax = plt.subplots(1, figsize=(20, 5))\n",
        "ax.plot(df_gbdt.index, forecast, label='Forecast')\n",
        "ax.plot(df_gbdt.index, df_gbdt['inc'], label='Actuals')\n",
        "ax.axvline(x=data_all.index[int(len(df_gbdt) * train_ratio)], linestyle='--')\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQks7i8QvGQu"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
        "\n",
        "forecast = model.predict(x_test)\n",
        "df_forecast = y_test.to_frame()\n",
        "df_forecast['lgbm_base'] = forecast\n",
        "print(mean_absolute_error(y_test, forecast))\n",
        "print(mean_absolute_percentage_error(y_test, forecast))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcwEVmPUv8vg"
      },
      "source": [
        "## добавим тренд\n",
        "на трейне:\n",
        "\n",
        "    1) обучим лин модель на временных метках.\n",
        "    2) делим/вычитаем тренд в зависимости от типа сезонности\n",
        "    3) на остатках обучаем бустинг\n",
        "\n",
        "на тесте:\n",
        "\n",
        "    1) делаем прогнозы бустингом\n",
        "    2) делаем прогнозы тренда\n",
        "    3) собираем все вместе"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oHubB4hev-mz"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "\n",
        "def detrending(df, trend_model, target_col='inc', seas_type='mult', dt_col='month'):\n",
        "    df_trend = df.reset_index()\n",
        "    X = df_trend.index.values\n",
        "    y = df_trend[target_col].values\n",
        "    trend_model.fit(X.reshape(-1, 1), y)\n",
        "    y_pred = trend_model.predict(X.reshape(-1, 1))\n",
        "    target_col_detrended = target_col + '_detrended'\n",
        "    if seas_type not in ['add', 'mult']:\n",
        "        raise ValueError('seas_type should be mult or add')\n",
        "    elif seas_type == 'mult':\n",
        "        df_trend[target_col_detrended] = df_trend[target_col] / y_pred\n",
        "    else:\n",
        "        df_trend[target_col_detrended] = df_trend[target_col] - y_pred\n",
        "    df_trend = df_trend.set_index(dt_col)[[target_col_detrended]]\n",
        "    df_trend['trend'] = y_pred\n",
        "    return df_trend, trend_model, y_pred\n",
        "\n",
        "\n",
        "def predict_trend(y_train, df_test, trend_model, target_col='inc'):\n",
        "    try:\n",
        "        last_val = y_train.iloc[-1].values[0]\n",
        "    except:\n",
        "        last_val = y_train.iloc[-1]\n",
        "    trend_predicts = []\n",
        "    for _ in range(df_test.shape[0]):\n",
        "        val = last_val + trend_model.coef_[0]\n",
        "        last_val = val\n",
        "        trend_predicts.append(val)\n",
        "    df_test['trend'] = trend_predicts\n",
        "    return df_test\n",
        "\n",
        "\n",
        "def restore_trend(y_pred_detr, df_test, seas_type='mult', col='trend'):\n",
        "    if seas_type not in ['add', 'mult']:\n",
        "        raise ValueError('seas_type should be mult or add')\n",
        "    elif seas_type == 'mult':\n",
        "        y_pred = y_pred_detr * df_test[col].values\n",
        "    else:\n",
        "        y_pred = y_pred_detr + df_test[col].values\n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrA1kSNXVYCg"
      },
      "outputs": [],
      "source": [
        "# сохраним фичи\n",
        "feats_cols = x_train.columns\n",
        "feats_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6bdefcskGLK"
      },
      "outputs": [],
      "source": [
        "# учимся тренду, убираем его и делаем прогноз\n",
        "y_train_detrended, trend_lr, trend_ex = detrending(y_train, LinearRegression())\n",
        "y_test_trend = predict_trend(y_train, x_test, trend_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdU8BmrGkHSy"
      },
      "outputs": [],
      "source": [
        "y_train.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMP2jLs7H5gO"
      },
      "outputs": [],
      "source": [
        "y_train_detrended['inc_detrended'].plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtJlI8s3IYWF"
      },
      "outputs": [],
      "source": [
        "y_train_detrended['trend'].plot()\n",
        "y_test_trend.trend.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePns4pSXKaK9"
      },
      "outputs": [],
      "source": [
        "# обучаем бустинг без тренда\n",
        "model = fit_lightgbm(x_train[feats_cols],\n",
        "                     y_train_detrended['inc_detrended']);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkfqHs7xMU6d"
      },
      "outputs": [],
      "source": [
        "# убедимся, что обучились без тренда\n",
        "plt.plot(y_train_detrended['inc_detrended'].values, color='blue')\n",
        "plt.plot(model.predict(x_train[feats_cols]), color='red')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfXXItEVVlIH"
      },
      "outputs": [],
      "source": [
        "# вернем тренд\n",
        "y_pred_detr = model.predict(x_test[feats_cols])\n",
        "y_pred = restore_trend(y_pred_detr, y_test_trend)\n",
        "df_forecast['lgbm_trend'] = y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-vMjGWxX6HF"
      },
      "outputs": [],
      "source": [
        "print(mean_absolute_error(y_test, y_pred))\n",
        "print(mean_absolute_percentage_error(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NG3pG-MNZeSJ"
      },
      "outputs": [],
      "source": [
        "df_forecast.plot()\n",
        "y_train.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47haMkrE0x78"
      },
      "source": [
        "## сезонность\n",
        "\n",
        "на трейне:\n",
        "\n",
        "    1) обучим лин модель на временных метках.\n",
        "    2) делим/вычитаем тренд в зависимости от типа сезонности\n",
        "    3) для каждого периода вычисляем среднее значение и среднее средних\n",
        "    4) в зависимости от типа сезонности делим/вычитаем из средних периодов среднее средних => получили коэффициенты сезонности\n",
        "    5) исходные значения ряда делим/вычитаем на коэф сезонности\n",
        "    6) на ряде без сезонности обучаем лин модель и вычитаем/делим => ряд без сезонности и тренда\n",
        "    7) обучаем бустинг\n",
        "\n",
        "на тесте:\n",
        "\n",
        "    1) делаем прогнозы бустингом\n",
        "    2) делаем прогнозы тренда\n",
        "    3) делаем прогнозы сезонности\n",
        "    3) собираем все вместе"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWEIaT5wbJDO"
      },
      "outputs": [],
      "source": [
        "def get_seasonal(df, seas_type='mult', target_col='inc'):\n",
        "    lr = LinearRegression()\n",
        "    dt_col = df.index.name\n",
        "    df_trend = df.reset_index()\n",
        "    X = df_trend.index.values\n",
        "    y = df_trend[target_col].values\n",
        "    lr.fit(X.reshape(-1, 1), y)\n",
        "    y_pred = lr.predict(X.reshape(-1, 1))\n",
        "    if seas_type not in ['add', 'mult']:\n",
        "        raise ValueError('seas_type should be mult or add')\n",
        "    elif seas_type == 'mult':\n",
        "        df_trend['detrended'] = df_trend[target_col] / y_pred\n",
        "    else:\n",
        "        df_trend['detrended'] = df_trend[target_col] - y_pred\n",
        "    df_trend['period'] = df_trend[dt_col].dt.month\n",
        "    df_agg = df_trend\\\n",
        "        .groupby('period')\\\n",
        "        .agg({'detrended': 'mean'})\\\n",
        "        .reset_index()\n",
        "    mean_mean = df_agg['detrended'].mean()\n",
        "    if seas_type not in ['add', 'mult']:\n",
        "        raise ValueError('seas_type should be mult or add')\n",
        "    elif seas_type == 'mult':\n",
        "        df_agg['seasonal'] = df_agg['detrended'] / mean_mean\n",
        "    else:\n",
        "        df_agg['seasonal'] = df_agg['detrended'] - mean_mean\n",
        "    df_trend = df_trend.merge(df_agg[['period', 'seasonal']], on='period', how='inner')\n",
        "    return df_trend.set_index(dt_col)['seasonal'], df_agg\n",
        "\n",
        "\n",
        "def deseason(df, df_seasonal, seas_type='mult', target_col='inc'):\n",
        "    df_deseas = pd.concat((df, df_seasonal), axis=1)\n",
        "    if seas_type not in ['add', 'mult']:\n",
        "        raise ValueError('seas_type should be mult or add')\n",
        "    elif seas_type == 'mult':\n",
        "        df_deseas['deseason'] = df_deseas[target_col] / df_deseas['seasonal']\n",
        "    else:\n",
        "        df_deseas['detrended'] = df_deseas[target_col] - df_deseas['seasonal']\n",
        "    return df_deseas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHPsaDnU4m_9"
      },
      "outputs": [],
      "source": [
        "df_seas, df_agg = get_seasonal(y_train, seas_type='mult')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MusOfcV3pCh"
      },
      "outputs": [],
      "source": [
        "df_agg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1SkFPJ28MNH"
      },
      "outputs": [],
      "source": [
        "df_deseas = deseason(y_train, df_seas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KD8A_zA2AONV"
      },
      "outputs": [],
      "source": [
        "df_deseas['inc'].plot(kind='line', figsize=(8, 4), title='inc')\n",
        "plt.gca().spines[['top', 'right']].set_visible(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wlo3rucAk99"
      },
      "outputs": [],
      "source": [
        "df_deseas['seasonal'].plot(kind='line', figsize=(8, 4), title='inc')\n",
        "plt.gca().spines[['top', 'right']].set_visible(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HREfzB6o_tIt"
      },
      "outputs": [],
      "source": [
        "df_deseas['deseason'].plot(kind='line', figsize=(8, 4), title='inc')\n",
        "plt.gca().spines[['top', 'right']].set_visible(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvloxP2qAdsZ"
      },
      "outputs": [],
      "source": [
        "df_deseas_detr, lr_trend, trend_ex  = detrending(df_deseas,\n",
        "                                                 LinearRegression(),\n",
        "                                                 target_col='deseason',\n",
        "                                                 seas_type='mult')\n",
        "y_test_trend = predict_trend(df_deseas_detr['trend'], x_test, lr_trend, target_col='deseason')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4XrTPf9GFZu"
      },
      "outputs": [],
      "source": [
        "df_deseas_detr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXVozexPE2HK"
      },
      "outputs": [],
      "source": [
        "df_deseas_detr['trend'].plot()\n",
        "y_test_trend.trend.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ICofUJAB7FJ"
      },
      "outputs": [],
      "source": [
        "df_deseas_detr.deseason_detrended.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKXh3aaVB8Vp"
      },
      "outputs": [],
      "source": [
        "model = fit_lightgbm(x_train[feats_cols],\n",
        "                     df_deseas_detr['deseason_detrended']);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQWpwry9DZ8p"
      },
      "outputs": [],
      "source": [
        "plt.plot(df_deseas_detr.deseason_detrended.values)\n",
        "plt.plot(model.predict(x_train[feats_cols]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlGIVnDkDf5d"
      },
      "outputs": [],
      "source": [
        "# вернем тренд\n",
        "x_test = x_test.sort_index()\n",
        "# y_pred_deseas_detr = model.predict(x_test[feats_cols])\n",
        "x_test['pred_lgbm'] = model.predict(x_test[feats_cols])\n",
        "x_test = x_test.merge(y_test_trend['trend'], how='inner')\n",
        "x_test['pred'] = x_test['pred_lgbm'] + x_test['trend']\n",
        "# y_pred = restore_trend(y_pred_deseas_detr, y_test_trend, seas_type='add')\n",
        "# вернем сезонность\n",
        "# x_test['pred'] = y_pred\n",
        "# x_test_upd = x_test.assign(period=x_test.index.month)\\\n",
        "#                         .merge(df_agg[['period', 'seasonal']],\n",
        "#                                on='period',\n",
        "#                                how='inner')\n",
        "# x_test_upd['pred'] = x_test_upd['pred'] * x_test_upd['seasonal']\n",
        "x_test = x_test.merge(df_agg[['period', 'seasonal']],\n",
        "                               left_on='month',\n",
        "                                right_on='period',\n",
        "                               how='inner')\n",
        "x_test['pred'] = x_test['seasonal'] * x_test['pred']\n",
        "y_pred = x_test['pred'].values\n",
        "# # y_pred = restore_trend(y_pred,\n",
        "# #                        y_test_trend\\\n",
        "# #                         .assign(period=y_test_trend.index.month)\\\n",
        "# #                         .merge(df_agg[['period', 'seasonal']],\n",
        "# #                                on='period',\n",
        "# #                                how='inner'),\n",
        "# #                        seas_type='mult', col='seasonal')\n",
        "df_forecast['lgbm_des_trend'] = y_pred\n",
        "# print(mean_absolute_error(y_test, y_pred))\n",
        "# print(mean_absolute_percentage_error(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HM66t9avGYRK"
      },
      "outputs": [],
      "source": [
        "df_forecast.plot()\n",
        "y_train.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wb188rtOCLT2"
      },
      "source": [
        "## все ли делаем правильно?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zud4OY9rN1-Y"
      },
      "source": [
        "### trend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GcuSTV7IJT8"
      },
      "outputs": [],
      "source": [
        "test_start = x_test.index.min()\n",
        "data_train = data_all[data_all.index < pd.to_datetime(test_start)].copy()\n",
        "data_test = data_all[data_all.index >= pd.to_datetime(test_start)].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hT2OVzQWegfY"
      },
      "outputs": [],
      "source": [
        "data_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FuzdixFqBKj"
      },
      "outputs": [],
      "source": [
        "data_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUCSReMMCcO4"
      },
      "outputs": [],
      "source": [
        "# учимся тренду, убираем его и делаем прогноз\n",
        "y_train_detrended, trend_lr, trend_ex = detrending(data_train, LinearRegression())\n",
        "y_test_trend = predict_trend(data_train, data_test, trend_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9Jnh-VTCfKa"
      },
      "outputs": [],
      "source": [
        "y_train_detrended['inc_detrended'].plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INd_1CMrDl1d"
      },
      "outputs": [],
      "source": [
        "y_train_detrended['trend'].plot()\n",
        "y_test_trend.trend.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vV9AY9ShE9mo"
      },
      "outputs": [],
      "source": [
        "def splitXy(df, col_y):\n",
        "    return df.drop(columns=[col_y]), df[col_y]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joAhn81iEW93"
      },
      "outputs": [],
      "source": [
        "# обучаем бустинг без тренда\n",
        "# вот теперь считаем фичи\n",
        "\n",
        "df_gbdt_train = features_regression(y_train_detrended, target_col='inc_detrended')\n",
        "x_train, y_train = splitXy(df_gbdt_train, 'inc_detrended')\n",
        "df_gbdt_test = features_regression(pd.concat((y_train_detrended,\n",
        "                                              data_test\\\n",
        "                                              .assign(inc_detrended=data_test.inc / data_test.trend)),\n",
        "                                              axis=0),\n",
        "                                   target_col='inc_detrended')\n",
        "df_gbdt_test = df_gbdt_test[df_gbdt_test.index >= test_start]\n",
        "x_test, y_test = splitXy(df_gbdt_test, 'inc_detrended')\n",
        "\n",
        "model = fit_lightgbm(x_train,\n",
        "                     y_train);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Atx_J-xzK8RG"
      },
      "outputs": [],
      "source": [
        "plt.plot(y_train.values)\n",
        "plt.plot(model.predict(x_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gii5BxIbMmzu"
      },
      "outputs": [],
      "source": [
        "# вернем тренд\n",
        "y_pred_detr = model.predict(x_test)\n",
        "y_pred = restore_trend(y_pred_detr, y_test_trend)\n",
        "df_forecast['lgbm_trend'] = y_pred\n",
        "\n",
        "print(mean_absolute_error(data_test.inc.values, y_pred))\n",
        "print(mean_absolute_percentage_error(data_test.inc.values, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYUZzA3HNW2E"
      },
      "outputs": [],
      "source": [
        "df_forecast.plot()\n",
        "data_train.inc.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ViRADeOjOehC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "380.594px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
